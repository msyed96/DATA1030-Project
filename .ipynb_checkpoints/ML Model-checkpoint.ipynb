{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 1030 : Project Code: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
      "\n",
      "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
      "0      4        3      4     1     1      3        6   5   6   6  \n",
      "1      5        3      3     1     1      3        4   5   5   6  \n",
      "2      4        3      2     2     3      3       10   7   8  10  \n",
      "3      3        2      2     1     1      5        2  15  14  15  \n",
      "4      4        3      2     1     2      5        4   6  10  10  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "df= pd.read_csv('student-mat.csv', delimiter = ';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### G3 <10 is Fail while G3 >= 10 = Pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['G3'] = df['G3'].map({0:'<10', 1:'<10', 2:'<10' , 3:'<10', 4:'<10', 5:'<10', 6:'<10', 7:'<10', \n",
    "                                   8:'<10',9:'<10',10:'>=10',11:'>=10', 12:'>=10',13:'>=10',14:'>=10',15:'>=10',\n",
    "                                   16:'>=10',17:'>=10',18:'>=10',19:'>=10', 20:'>=10'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding on Target Variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "class_values = le.fit_transform(df[['G3']])\n",
    "df_class= pd.DataFrame(class_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['G3'] = df_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing X and y for my Machine learning Pipeline & Calculating Balance of the data:\n",
    "##### Keep in mind that I have three models \n",
    "        - Model I: Includes G1, G2 \n",
    "        - Model II: Includes G1\n",
    "        - Model III: Does not include G1 or G2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model I: With G1 and G2\n",
    "##### Model I:  X and y values, Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance: 0.6708860759493671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
       "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
       "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
       "       'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'G3']\n",
    "y = df['G3']\n",
    "\n",
    "classes, counts = np.unique(y,return_counts=True)\n",
    "print('balance:',np.max(counts/len(y)))\n",
    "ftr_names= X.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model I Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Logistic Regression parameter tuning for model I: \n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV_logistic(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences','G1','G2']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor, LogisticRegression(penalty='l1', solver='saga', max_iter=10000, random_state = 20))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'logisticregression__C': np.logspace(-2,2, num=8)} \n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, grid.score(X_test, y_test), np.array(feature_names), X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.13894954943731375}\n",
      "0\n",
      "best CV score: 0.9113924050632911\n",
      "test score: 0.8607594936708861\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "1\n",
      "best CV score: 0.9367088607594937\n",
      "test score: 0.8734177215189873\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "2\n",
      "best CV score: 0.9208860759493671\n",
      "test score: 0.8860759493670886\n",
      "{'logisticregression__C': 1.9306977288832496}\n",
      "3\n",
      "best CV score: 0.9208860759493671\n",
      "test score: 0.8860759493670886\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "4\n",
      "best CV score: 0.9272151898734177\n",
      "test score: 0.8860759493670886\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "5\n",
      "best CV score: 0.9145569620253164\n",
      "test score: 0.8860759493670886\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "6\n",
      "best CV score: 0.9430379746835443\n",
      "test score: 0.9113924050632911\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "7\n",
      "best CV score: 0.9272151898734177\n",
      "test score: 0.9367088607594937\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "8\n",
      "best CV score: 0.9208860759493671\n",
      "test score: 0.8734177215189873\n",
      "{'logisticregression__C': 1.9306977288832496}\n",
      "9\n",
      "best CV score: 0.930379746835443\n",
      "test score: 0.9367088607594937\n",
      "test accuracy: 0.8936708860759494 +/- 0.024804959420589145\n"
     ]
    }
   ],
   "source": [
    "#print confusion_matrix(y, y_pred)\n",
    "test_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    grid, test_score,feature_names, X_test, y_test = ML_pipeline_kfold_GridSearchCV_logistic(X,y,i*19, 5)\n",
    "    print(grid.best_params_)\n",
    "    print(i)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9272151898734177\n",
      "0.9367088607594937\n",
      "{'logisticregression__C': 0.517947467923121}\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_logistic(X,y,7*19,5)\n",
    "print(grid.best_score_)\n",
    "print(grid.score(X_test,y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('columntransformer',\n",
      "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
      "                                   sparse_threshold=0.3,\n",
      "                                   transformer_weights=None,\n",
      "                                   transformers=[('num',\n",
      "                                                  Pipeline(memory=None,\n",
      "                                                           steps=[('scaler',\n",
      "                                                                   StandardScaler(copy=True,\n",
      "                                                                                  with_mean=True,\n",
      "                                                                                  with_std=True))],\n",
      "                                                           verbose=False),\n",
      "                                                  [2, 29, 30, 31]),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(memory=None,\n",
      "                                                           steps=[('onehot',\n",
      "                                                                   OneHotEncoder(cate...\n",
      "                                                  [0, 1, 3, 5, 4, 15, 16, 17,\n",
      "                                                   18, 19, 8, 9, 10, 11, 20, 21,\n",
      "                                                   22])],\n",
      "                                   verbose=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=0.517947467923121, class_weight=None,\n",
      "                                    dual=False, fit_intercept=True,\n",
      "                                    intercept_scaling=1, l1_ratio=None,\n",
      "                                    max_iter=10000, multi_class='warn',\n",
      "                                    n_jobs=None, penalty='l1', random_state=20,\n",
      "                                    solver='saga', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n",
      "0.9272151898734177\n",
      "3\n",
      "[[20  1]\n",
      " [ 4 54]]\n",
      "[[0.95238095 0.04761905]\n",
      " [0.06896552 0.93103448]]\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_index_)\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)\n",
    "normalized_conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "print(normalized_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model I Random Forest Classifier\n",
    "###Logistic Regression parameter tuning for model I: \n",
    "\n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV_rf(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences','G1','G2']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor, RandomForestClassifier(n_estimators =  100,random_state=random_state))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'randomforestclassifier__max_depth': range(1,30,5),\n",
    "                  'randomforestclassifier__min_samples_split': range(2,20,5)} \n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, grid.score(X_test, y_test), np.array(feature_names), X_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_depth': 16, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.9208860759493671\n",
      "test score: 0.8607594936708861\n",
      "{'randomforestclassifier__max_depth': 6, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.9208860759493671\n",
      "test score: 0.8481012658227848\n",
      "{'randomforestclassifier__max_depth': 16, 'randomforestclassifier__min_samples_split': 12}\n",
      "best CV score: 0.9335443037974683\n",
      "test score: 0.8734177215189873\n",
      "{'randomforestclassifier__max_depth': 6, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.8987341772151899\n",
      "test score: 0.8860759493670886\n",
      "{'randomforestclassifier__max_depth': 16, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.9145569620253164\n",
      "test score: 0.9113924050632911\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.930379746835443\n",
      "test score: 0.8734177215189873\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.9272151898734177\n",
      "test score: 0.8607594936708861\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 17}\n",
      "best CV score: 0.9145569620253164\n",
      "test score: 0.9367088607594937\n",
      "{'randomforestclassifier__max_depth': 16, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.9240506329113924\n",
      "test score: 0.8607594936708861\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.9177215189873418\n",
      "test score: 0.8860759493670886\n",
      "test accuracy: 0.879746835443038 +/- 0.02547419214873177\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score, feature_names, X_test, y_test = ML_pipeline_kfold_GridSearchCV_rf(X,y,i*19,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9145569620253164\n",
      "0.9367088607594937\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 17}\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_rf(X,y,7*19,5)\n",
    "print(grid.best_score_)\n",
    "print(grid.score(X_test,y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('columntransformer',\n",
      "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
      "                                   sparse_threshold=0.3,\n",
      "                                   transformer_weights=None,\n",
      "                                   transformers=[('num',\n",
      "                                                  Pipeline(memory=None,\n",
      "                                                           steps=[('scaler',\n",
      "                                                                   StandardScaler(copy=True,\n",
      "                                                                                  with_mean=True,\n",
      "                                                                                  with_std=True))],\n",
      "                                                           verbose=False),\n",
      "                                                  [2, 29, 30, 31]),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(memory=None,\n",
      "                                                           steps=[('onehot',\n",
      "                                                                   OneHotEncoder(cate...\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=11,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1,\n",
      "                                        min_samples_split=17,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=133,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "0.9145569620253164\n",
      "11\n",
      "[[20  1]\n",
      " [ 4 54]]\n",
      "[[0.95238095 0.04761905]\n",
      " [0.06896552 0.93103448]]\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test = ML_pipeline_kfold_GridSearchCV_rf(X,y,7*19,5)\n",
    "# results = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_index_)\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "# conf_mat = confusion_matrix(y_test, y_pred)\n",
    "# print(conf_mat)\n",
    "# normalized_conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "# print(normalized_conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model I SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV_svc(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences','G1','G2']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor,SVC(random_state = 20))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],'svc__gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]} \n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, grid.score(X_test, y_test), np.array(feature_names), X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.9177215189873418\n",
      "test score: 0.9240506329113924\n",
      "{'svc__C': 10, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9240506329113924\n",
      "test score: 0.8987341772151899\n",
      "{'svc__C': 10000, 'svc__gamma': 0.0001}\n",
      "best CV score: 0.9145569620253164\n",
      "test score: 0.8734177215189873\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.9208860759493671\n",
      "test score: 0.8860759493670886\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.9050632911392406\n",
      "test score: 0.9113924050632911\n",
      "{'svc__C': 1000, 'svc__gamma': 0.0001}\n",
      "best CV score: 0.9145569620253164\n",
      "test score: 0.9113924050632911\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.9367088607594937\n",
      "test score: 0.8481012658227848\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.9050632911392406\n",
      "test score: 0.9620253164556962\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.9240506329113924\n",
      "test score: 0.8607594936708861\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8987341772151899\n",
      "test score: 0.9240506329113924\n",
      "test accuracy: 0.8999999999999998 +/- 0.03224744101989114\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_svc(X,y,i*19,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9050632911392406\n",
      "0.9620253164556962\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_svc(X,y,7*19,5)\n",
    "print(grid.best_score_)\n",
    "print(grid.score(X_test,y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model II - With G1 without G2\n",
    "##### Model II - Data prep, X and y values, Balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['G2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  romantic famrel  freetime  goout  Dalc Walc health absences  G1 G3  \n",
       "0       no      4         3      4     1    1      3        6   5  0  \n",
       "1       no      5         3      3     1    1      3        4   5  0  \n",
       "2       no      4         3      2     2    3      3       10   7  1  \n",
       "3      yes      3         2      2     1    1      5        2  15  1  \n",
       "4       no      4         3      2     1    2      5        4   6  1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.loc[:, df1.columns != 'G3']\n",
    "y = df1['G3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model II Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model II: Logistic Regression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "###Logistic Regression parameter tuning for model I: \n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV_logistic(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences','G1']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor, LogisticRegression(penalty='l1', solver='saga', max_iter=10000, random_state = 20))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'logisticregression__C': np.logspace(-2,2, num=8)} \n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, grid.score(X_test, y_test), np.array(feature_names), X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.13894954943731375}\n",
      "best CV score: 0.8322784810126582\n",
      "test score: 0.8987341772151899\n",
      "{'logisticregression__C': 0.13894954943731375}\n",
      "best CV score: 0.8544303797468354\n",
      "test score: 0.8227848101265823\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "best CV score: 0.8670886075949367\n",
      "test score: 0.7848101265822784\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "best CV score: 0.8607594936708861\n",
      "test score: 0.759493670886076\n",
      "{'logisticregression__C': 1.9306977288832496}\n",
      "best CV score: 0.8512658227848101\n",
      "test score: 0.8227848101265823\n",
      "{'logisticregression__C': 0.13894954943731375}\n",
      "best CV score: 0.8354430379746836\n",
      "test score: 0.8481012658227848\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "best CV score: 0.8734177215189873\n",
      "test score: 0.7468354430379747\n",
      "{'logisticregression__C': 1.9306977288832496}\n",
      "best CV score: 0.8417721518987342\n",
      "test score: 0.8481012658227848\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "best CV score: 0.8639240506329114\n",
      "test score: 0.810126582278481\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "best CV score: 0.8449367088607594\n",
      "test score: 0.8734177215189873\n",
      "test accuracy: 0.8215189873417721 +/- 0.045797601304115296\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score,feature_names, X_test, y_test = ML_pipeline_kfold_GridSearchCV_logistic(X,y,i*19, 5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8417721518987342\n",
      "0.8481012658227848\n",
      "{'logisticregression__C': 1.9306977288832496}\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_logistic(X,y,7*19,5)\n",
    "print(grid.best_score_)\n",
    "print(grid.score(X_test,y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model II: Random Forest Classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model II: Random Forest Classifier: \n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV_rf(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences','G1']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor, RandomForestClassifier(n_estimators =  100,random_state=random_state))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'randomforestclassifier__max_depth': range(1,30,5),\n",
    "                  'randomforestclassifier__min_samples_split': range(2,20,5)} \n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, grid.score(X_test, y_test), np.array(feature_names), X_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 12}\n",
      "best CV score: 0.8291139240506329\n",
      "test score: 0.810126582278481\n",
      "{'randomforestclassifier__max_depth': 6, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.8354430379746836\n",
      "test score: 0.8607594936708861\n",
      "{'randomforestclassifier__max_depth': 16, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.8322784810126582\n",
      "test score: 0.8227848101265823\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.8575949367088608\n",
      "test score: 0.759493670886076\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.8069620253164557\n",
      "test score: 0.8607594936708861\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.8259493670886076\n",
      "test score: 0.8354430379746836\n",
      "{'randomforestclassifier__max_depth': 16, 'randomforestclassifier__min_samples_split': 17}\n",
      "best CV score: 0.8575949367088608\n",
      "test score: 0.759493670886076\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.8227848101265823\n",
      "test score: 0.8354430379746836\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 12}\n",
      "best CV score: 0.8227848101265823\n",
      "test score: 0.7721518987341772\n",
      "{'randomforestclassifier__max_depth': 6, 'randomforestclassifier__min_samples_split': 12}\n",
      "best CV score: 0.8227848101265823\n",
      "test score: 0.8227848101265823\n",
      "test accuracy: 0.8139240506329115 +/- 0.036269743751631396\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score,feature_names, X_test, y_test = ML_pipeline_kfold_GridSearchCV_rf(X,y,i*19, 5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8227848101265823\n",
      "0.8354430379746836\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_rf(X,y,7*19,5)\n",
    "print(grid.best_score_)\n",
    "print(grid.score(X_test,y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model II: SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model II SVC:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV_svc(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences','G1']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor,SVC(random_state = 20))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],'svc__gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]} \n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, grid.score(X_test, y_test), np.array(feature_names), X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 1, 'svc__gamma': 0.1}\n",
      "best CV score: 0.8386075949367089\n",
      "test score: 0.8607594936708861\n",
      "{'svc__C': 1, 'svc__gamma': 0.01}\n",
      "best CV score: 0.8481012658227848\n",
      "test score: 0.8607594936708861\n",
      "{'svc__C': 10, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8386075949367089\n",
      "test score: 0.7088607594936709\n",
      "{'svc__C': 1000, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8607594936708861\n",
      "test score: 0.759493670886076\n",
      "{'svc__C': 1000, 'svc__gamma': 0.0001}\n",
      "best CV score: 0.8449367088607594\n",
      "test score: 0.8354430379746836\n",
      "{'svc__C': 1, 'svc__gamma': 0.01}\n",
      "best CV score: 0.8164556962025317\n",
      "test score: 0.8354430379746836\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8765822784810127\n",
      "test score: 0.7468354430379747\n",
      "{'svc__C': 100, 'svc__gamma': 0.01}\n",
      "best CV score: 0.8386075949367089\n",
      "test score: 0.7974683544303798\n",
      "{'svc__C': 10, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8322784810126582\n",
      "test score: 0.8227848101265823\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.8227848101265823\n",
      "test score: 0.8354430379746836\n",
      "test accuracy: 0.8063291139240507 +/- 0.049041444627368404\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score,feature_names, X_test, y_test = ML_pipeline_kfold_GridSearchCV_svc(X,y,i*19, 5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8386075949367089\n",
      "0.7974683544303798\n",
      "{'svc__C': 100, 'svc__gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_svc(X,y,7*19,5)\n",
    "print(grid.best_score_)\n",
    "print(grid.score(X_test,y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model III - No G1 & G2\n",
    "##### Data prep for X and y and Balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(['G1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, df2.columns != 'G3']\n",
    "y = df2['G3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model III - Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Model III - Logistic Regression \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV_logistic(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor, LogisticRegression(penalty='l1', solver='saga', max_iter=10000, random_state = 20))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'logisticregression__C': np.logspace(-2,2, num=8)} \n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, grid.score(X_test, y_test), np.array(feature_names), X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.13894954943731375}\n",
      "best CV score: 0.6867088607594937\n",
      "test score: 0.6329113924050633\n",
      "{'logisticregression__C': 0.01}\n",
      "best CV score: 0.6582278481012658\n",
      "test score: 0.7215189873417721\n",
      "{'logisticregression__C': 0.517947467923121}\n",
      "best CV score: 0.689873417721519\n",
      "test score: 0.5569620253164557\n",
      "{'logisticregression__C': 0.13894954943731375}\n",
      "best CV score: 0.6740506329113924\n",
      "test score: 0.6708860759493671\n",
      "{'logisticregression__C': 0.13894954943731375}\n",
      "best CV score: 0.6740506329113924\n",
      "test score: 0.6835443037974683\n",
      "{'logisticregression__C': 1.9306977288832496}\n",
      "best CV score: 0.6677215189873418\n",
      "test score: 0.7215189873417721\n",
      "{'logisticregression__C': 0.13894954943731375}\n",
      "best CV score: 0.6582278481012658\n",
      "test score: 0.7341772151898734\n",
      "{'logisticregression__C': 0.13894954943731375}\n",
      "best CV score: 0.6582278481012658\n",
      "test score: 0.7341772151898734\n",
      "{'logisticregression__C': 0.13894954943731375}\n",
      "best CV score: 0.6772151898734177\n",
      "test score: 0.6708860759493671\n",
      "{'logisticregression__C': 0.01}\n",
      "best CV score: 0.6550632911392406\n",
      "test score: 0.7341772151898734\n",
      "test accuracy: 0.6860759493670887 +/- 0.0542386969256419\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score,feature_names, X_test, y_test = ML_pipeline_kfold_GridSearchCV_logistic(X,y,i*19, 5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6582278481012658\n",
      "0.7341772151898734\n",
      "{'logisticregression__C': 0.13894954943731375}\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_logistic(X,y,7*19,5)\n",
    "print(grid.best_score_)\n",
    "print(grid.score(X_test,y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model III: Random Forest Classifier: \n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV_rf(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor, RandomForestClassifier(n_estimators =  100,random_state=random_state))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'randomforestclassifier__max_depth': range(1,30,5),\n",
    "                  'randomforestclassifier__min_samples_split': range(2,20,5)} \n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, grid.score(X_test, y_test), np.array(feature_names), X_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_depth': 1, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.6835443037974683\n",
      "test score: 0.620253164556962\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.6930379746835443\n",
      "test score: 0.620253164556962\n",
      "{'randomforestclassifier__max_depth': 6, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.6677215189873418\n",
      "test score: 0.6962025316455697\n",
      "{'randomforestclassifier__max_depth': 6, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.680379746835443\n",
      "test score: 0.6708860759493671\n",
      "{'randomforestclassifier__max_depth': 1, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.6487341772151899\n",
      "test score: 0.759493670886076\n",
      "{'randomforestclassifier__max_depth': 1, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.6645569620253164\n",
      "test score: 0.6962025316455697\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 12}\n",
      "best CV score: 0.6708860759493671\n",
      "test score: 0.6962025316455697\n",
      "{'randomforestclassifier__max_depth': 6, 'randomforestclassifier__min_samples_split': 7}\n",
      "best CV score: 0.7088607594936709\n",
      "test score: 0.5443037974683544\n",
      "{'randomforestclassifier__max_depth': 11, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.6613924050632911\n",
      "test score: 0.7341772151898734\n",
      "{'randomforestclassifier__max_depth': 1, 'randomforestclassifier__min_samples_split': 2}\n",
      "best CV score: 0.6550632911392406\n",
      "test score: 0.7341772151898734\n",
      "test accuracy: 0.6772151898734178 +/- 0.06207696119108472\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score, feature_name, X_test, y_test = ML_pipeline_kfold_GridSearchCV_rf(X,y,i*42,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    \n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6550632911392406\n",
      "0.7341772151898734\n",
      "{'randomforestclassifier__max_depth': 1, 'randomforestclassifier__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_rf(X,y,7*19,5)\n",
    "print(grid.best_score_)\n",
    "print(grid.score(X_test,y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model II SVC:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "def ML_pipeline_kfold_GridSearchCV_svc(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor,SVC(random_state = 20))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],'svc__gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]} \n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True,iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, grid.score(X_test, y_test), np.array(feature_names), X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 10, 'svc__gamma': 0.01}\n",
      "best CV score: 0.6867088607594937\n",
      "test score: 0.6329113924050633\n",
      "{'svc__C': 100, 'svc__gamma': 0.001}\n",
      "best CV score: 0.6867088607594937\n",
      "test score: 0.6329113924050633\n",
      "{'svc__C': 0.001, 'svc__gamma': 1e-05}\n",
      "best CV score: 0.6645569620253164\n",
      "test score: 0.6962025316455697\n",
      "{'svc__C': 0.001, 'svc__gamma': 1e-05}\n",
      "best CV score: 0.6772151898734177\n",
      "test score: 0.6455696202531646\n",
      "{'svc__C': 1, 'svc__gamma': 1}\n",
      "best CV score: 0.6550632911392406\n",
      "test score: 0.759493670886076\n",
      "{'svc__C': 1, 'svc__gamma': 1}\n",
      "best CV score: 0.6677215189873418\n",
      "test score: 0.6962025316455697\n",
      "{'svc__C': 0.001, 'svc__gamma': 1e-05}\n",
      "best CV score: 0.6613924050632911\n",
      "test score: 0.7088607594936709\n",
      "{'svc__C': 0.001, 'svc__gamma': 1e-05}\n",
      "best CV score: 0.7025316455696202\n",
      "test score: 0.5443037974683544\n",
      "{'svc__C': 1, 'svc__gamma': 1}\n",
      "best CV score: 0.6645569620253164\n",
      "test score: 0.7088607594936709\n",
      "{'svc__C': 0.001, 'svc__gamma': 1e-05}\n",
      "best CV score: 0.6550632911392406\n",
      "test score: 0.7341772151898734\n",
      "test accuracy: 0.6759493670886076 +/- 0.059426301743319\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score, feature_names, X_test, y_test = ML_pipeline_kfold_GridSearchCV_svc(X,y,i*42,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6582278481012658\n",
      "0.7215189873417721\n",
      "{'svc__C': 1, 'svc__gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "grid, test_score, feature_names, X_test, y_test= ML_pipeline_kfold_GridSearchCV_svc(X,y,7*19,5)\n",
    "print(grid.best_score_)\n",
    "print(grid.score(X_test,y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cehcking out features election modelI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'G3'].values\n",
    "y = df['G3'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def ML_pipeline_kfold_LR1(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "#     ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "#                     'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences', 'G1','G2']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor,LogisticRegression(penalty='l2',solver='lbfgs'))\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10,100]}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,cv=kf, return_train_score = True,n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, np.array(feature_names), X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.9113924050632911\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid, feature_names, X_test, y_test = ML_pipeline_kfold_LR1(X,y,42,4)\n",
    "print('test score:',grid.score(X_test,y_test))\n",
    "coefs = grid.best_estimator_[-1].coef_[0]\n",
    "sorted_indcs = np.argsort(np.abs(coefs))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.barh(np.arange(10),coefs[sorted_indcs[-10:]])\n",
    "plt.yticks(np.arange(10),feature_names[sorted_indcs[-10:]])\n",
    "plt.xlabel('coefficient')\n",
    "plt.title('not all scaled')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/LR_coefs_notscaled.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_LR2(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "#     ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "#                     'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences', 'G1','G2']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "      \n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "    final_scaler = StandardScaler()\n",
    "    pipe = make_pipeline(preprocessor,final_scaler,LogisticRegression(penalty='l2',solver='lbfgs'))\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10,100]}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,cv=kf, return_train_score = True,n_jobs=-1,verbose=10)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, np.array(feature_names), X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, feature_names, X_test, y_test = ML_pipeline_kfold_LR2(X,y,42,4)\n",
    "print('test score:',grid.score(X_test,y_test))\n",
    "coefs = grid.best_estimator_[-1].coef_\n",
    "sorted_indcs = np.argsort(np.abs(coefs))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.barh(np.arange(10),coefs[sorted_indcs[-10:]])\n",
    "plt.yticks(np.arange(10),feature_names[sorted_indcs[-10:]])\n",
    "plt.xlabel('coefficient')\n",
    "plt.title('all scaled')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/LR_coefs_scaled.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['G2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.loc[:, df1.columns != 'G3'].values\n",
    "y = df1['G3'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def ML_pipeline_kfold_LR1(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "#     ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "#                     'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences', 'G1']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor,LogisticRegression(penalty='l2',solver='lbfgs'))\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10,100]}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,cv=kf, return_train_score = True,n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, np.array(feature_names), X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.8227848101265823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid, feature_names, X_test, y_test = ML_pipeline_kfold_LR1(X,y,42,4)\n",
    "print('test score:',grid.score(X_test,y_test))\n",
    "coefs = grid.best_estimator_[-1].coef_[0]\n",
    "sorted_indcs = np.argsort(np.abs(coefs))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.barh(np.arange(10),coefs[sorted_indcs[-10:]])\n",
    "plt.yticks(np.arange(10),feature_names[sorted_indcs[-10:]])\n",
    "plt.xlabel('coefficient')\n",
    "plt.title('not all scaled')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/LR_coefs_notscaled.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model iii:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(['G1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, df2.columns != 'G3'].values\n",
    "y = df2['G3'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def ML_pipeline_kfold_LR1(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "#     ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "#                     'traveltime','studytime', 'failures'] #already pre processd\n",
    "    num_ftrs = ['age','absences']\n",
    "    label = ['G3']\n",
    "    \n",
    "    cat_ftrs_i = [df.columns.get_loc(x) for x in cat_ftrs]\n",
    "    num_ftrs_i = [df.columns.get_loc(x) for x in num_ftrs]\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    # collect the transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs_i),\n",
    "            ('cat', categorical_transformer, cat_ftrs_i)])\n",
    "\n",
    "    pipe = make_pipeline(preprocessor,LogisticRegression(penalty='l2',solver='lbfgs'))\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10,100]}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,cv=kf, return_train_score = True,n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    feature_names = num_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid, np.array(feature_names), X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.6582278481012658\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid, feature_names, X_test, y_test = ML_pipeline_kfold_LR1(X,y,42,4)\n",
    "print('test score:',grid.score(X_test,y_test))\n",
    "coefs = grid.best_estimator_[-1].coef_[0]\n",
    "sorted_indcs = np.argsort(np.abs(coefs))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.barh(np.arange(10),coefs[sorted_indcs[-10:]])\n",
    "plt.yticks(np.arange(10),feature_names[sorted_indcs[-10:]])\n",
    "plt.xlabel('coefficient')\n",
    "plt.title('not all scaled')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/LR_coefs_notscaled.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance: 0.6708860759493671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(395, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'G3'].values\n",
    "y = df['G3'].values\n",
    "\n",
    "classes, counts = np.unique(y,return_counts=True)\n",
    "print('balance:',np.max(counts/len(y)))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = LabelEncoder().fit_transform(df[label])\n",
    "df.drop(columns=[label],inplace=True)\n",
    "X = df\n",
    "ftr_names = X.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# print(X.head())\n",
    "# print(y)\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None,\n",
    "                                        criterion='gini', max_depth=10,\n",
    "                                        max_features='auto',\n",
    "                                        max_leaf_nodes=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=1, min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=10, n_jobs=None,\n",
    "                                        oob_score=False, random_state=20,\n",
    "                                        verbose=0, warm_start=False)\n",
    "\n",
    "rf.fit(X_train, y_train)  \n",
    "print(rf.feature_importances_)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "features = X_train.columns\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = grid.best_estimator_[1].feature_importances_\n",
    "indices = np.argsort(importance)\n",
    "features = feau\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
