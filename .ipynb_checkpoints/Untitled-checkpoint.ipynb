{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib \n",
    "import numpy as np\n",
    "import matplotlib \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('student-mat.csv', delimiter = ';')\n",
    "\n",
    "df['G3'] = df['G3'].map({0:'<10', 1:'<10', 2:'<10' , 3:'<10', 4:'<10', 5:'<10', 6:'<10', 7:'<10', \n",
    "                                   8:'<10',9:'<10',10:'>=10',11:'>=10', 12:'>=10',13:'>=10',14:'>=10',15:'>=10',\n",
    "                                   16:'>=10',17:'>=10',18:'>=10',19:'>=10', 20:'>=10'})\n",
    "\n",
    "label = 'G3'\n",
    "\n",
    "y = LabelEncoder().fit_transform(df[label])\n",
    "df.drop(columns=[label],inplace=True)\n",
    "df.drop(columns=['G2'],inplace=True) ## un comment for model 2\n",
    "df.drop(columns=['G1'],inplace=True) ## un comment this and previous for model 3\n",
    "X = df\n",
    "ftr_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1: Random Forest\n",
    "def ML_pipeline_kfold_GridSearchCV_rf(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    cat_ftrs = ['school','sex','address','Pstatus','famsize','schoolsup','famsup','paid','activities','nursery',\n",
    "                    'Mjob', 'Fjob','reason', 'guardian', 'higher', 'internet', 'romantic']\n",
    "    ordinal_ftrs = ['Medu', 'Fedu', 'health','freetime', 'goout','famrel' 'Dalc', 'Walc', \n",
    "                'traveltime','studytime', 'failures'] #already pre processd\n",
    "    cont_ftrs = ['age','absences']\n",
    "    \n",
    "#     label = ['G3']\n",
    "    # one-hot encoder\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "    # standard scaler\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, cont_ftrs),\n",
    "            ('cat', categorical_transformer, cat_ftrs)])\n",
    "    pipe = make_pipeline(preprocessor,RandomForestClassifier(n_estimators =  100,random_state=random_state))\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'randomforestclassifier__max_depth': range(1,30,5),\n",
    "                  'randomforestclassifier__min_samples_split': range(2,20,5)}\n",
    "    # prepare gridsearch\n",
    "#     grid = GridSearchCV(pipe, param_grid=param_grid,cv=kf, return_train_score = True,n_jobs=-1,verbose=10)\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True, iid = False)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    feature_names = cont_ftrs + \\\n",
    "                list(grid.best_estimator_[0].named_transformers_['cat'][0].get_feature_names(cat_ftrs))\n",
    "    return grid,grid.score(X_test, y_test), np.array(feature_names), X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score, feature_names, X_test, y_test = ML_pipeline_kfold_GridSearchCV_rf(X,y,i*19, 5)\n",
    "    print(grid.best_params_)\n",
    "    print(i)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.mean(test_scores),'+/-',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs() # required for visualizations later on\n",
    "# create the explainer object with the random forest model\n",
    "explainer = shap.TreeExplainer(grid.best_estimator_[1])\n",
    "# transform the test set\n",
    "X_test_transformed = grid.best_estimator_[0].transform(X_test)\n",
    "print(np.shape(X_test_transformed))\n",
    "# calculate shap values on all points in the test\n",
    "shap_values = explainer.shap_values(X_test_transformed[:10])\n",
    "print(np.shape(shap_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 5 # the index of the point to explain\n",
    "print(explainer.expected_value[1]) # we explain class 1 predictions\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][index,:], features = X_test_transformed[index,:],feature_names = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_transformed[:10],feature_names = feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
